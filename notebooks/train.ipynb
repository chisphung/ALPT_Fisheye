{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe122c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv .venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854be36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from model.yolo.ultralytics.models.yolo.model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87051722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.204 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.202 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3904MiB)\n",
      "Ultralytics 8.3.202 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3904MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/chisphung/ALPR_Fisheye/dataset/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/home/chisphung/ALPR_Fisheye/configs/vertex-yolo.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=vertex_obb_train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/home/chisphung/ALPR_Fisheye/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/chisphung/ALPR_Fisheye/dataset/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/home/chisphung/ALPR_Fisheye/configs/vertex-yolo.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=vertex_obb_train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/home/chisphung/ALPR_Fisheye/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1   2851264  ultralytics.nn.modules.vertexnet.VertexBackbone[3, 128, True, [2, 3, 3]]     \n",
      "  1                   0  1         0  ultralytics.nn.modules.conv.Index            [0]                           \n",
      "  2                   0  1         0  ultralytics.nn.modules.conv.Index            [1]                           \n",
      "  3                   0  1         0  ultralytics.nn.modules.conv.Index            [2]                           \n",
      "  4           [1, 2, 3]  1   1370809  ultralytics.nn.modules.head.OBB              [2, 1, [128, 128, 128]]       \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1   2851264  ultralytics.nn.modules.vertexnet.VertexBackbone[3, 128, True, [2, 3, 3]]     \n",
      "  1                   0  1         0  ultralytics.nn.modules.conv.Index            [0]                           \n",
      "  2                   0  1         0  ultralytics.nn.modules.conv.Index            [1]                           \n",
      "  3                   0  1         0  ultralytics.nn.modules.conv.Index            [2]                           \n",
      "  4           [1, 2, 3]  1   1370809  ultralytics.nn.modules.head.OBB              [2, 1, [128, 128, 128]]       \n",
      "vertex-YOLO summary: 143 layers, 4,222,073 parameters, 4,222,057 gradients, 25.3 GFLOPs\n",
      "\n",
      "vertex-YOLO summary: 143 layers, 4,222,073 parameters, 4,222,057 gradients, 25.3 GFLOPs\n",
      "\n",
      "Freezing layer 'model.4.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Freezing layer 'model.4.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 179.2¬±82.6 MB/s, size: 173.1 KB)\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 179.2¬±82.6 MB/s, size: 173.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/chisphung/ALPR_Fisheye/dataset/labels/train.cache... 3433 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3433/3433 54.5Mit/s 0.0ss\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/chisphung/ALPR_Fisheye/dataset/labels/train.cache... 3433 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3433/3433 54.5Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 766.4¬±889.7 MB/s, size: 130.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/chisphung/ALPR_Fisheye/dataset/labels/val.cache... 1145 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1145/1145 11.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 766.4¬±889.7 MB/s, size: 130.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/chisphung/ALPR_Fisheye/dataset/labels/val.cache... 1145 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1145/1145 11.1Mit/s 0.0s\n",
      "Plotting labels to /home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2/labels.jpg... \n",
      "Plotting labels to /home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/chisphung/ALPR_Fisheye/runs/vertex_obb_train2\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[K      1/300      3.58G      2.611      3.642      4.143         34        640: 44% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 95/215 4.0it/s 36.5s<29.8s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/bin/yolo\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/cfg/__init__.py\", line 990, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/model.py\", line 800, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/trainer.py\", line 235, in train\n",
      "    self._do_train()\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/trainer.py\", line 423, in _do_train\n",
      "    loss, self.loss_items = self.model(batch)\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/nn/tasks.py\", line 140, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/nn/tasks.py\", line 341, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^C\n",
      "^object address  : 0x7d5770793460\n",
      "object refcount : 3\n",
      "object type     : 0xa36620\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n",
      "\u001b[K      1/300      3.58G      2.611      3.642      4.143         34        640: 44% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 95/215 4.0it/s 36.5s<29.8s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/bin/yolo\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/cfg/__init__.py\", line 990, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/model.py\", line 800, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/trainer.py\", line 235, in train\n",
      "    self._do_train()\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/engine/trainer.py\", line 423, in _do_train\n",
      "    loss, self.loss_items = self.model(batch)\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/nn/tasks.py\", line 140, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chisphung/ALPR_Fisheye/model/yolo/ultralytics/nn/tasks.py\", line 341, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^C\n",
      "^object address  : 0x7d5770793460\n",
      "object refcount : 3\n",
      "object type     : 0xa36620\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n"
     ]
    }
   ],
   "source": [
    "!yolo obb train \\\n",
    "    model=/home/chisphung/ALPR_Fisheye/configs/vertex-yolo.yaml \\\n",
    "    data=/home/chisphung/ALPR_Fisheye/dataset/dataset.yaml \\\n",
    "    imgsz=640 \\\n",
    "    epochs=300 \\\n",
    "    batch=16 \\\n",
    "    device=0 \\\n",
    "    project=/home/chisphung/ALPR_Fisheye/runs \\\n",
    "    name=vertex_obb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b609d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "tracks = os.listdir('/home/chisphung/ALPR_Fisheye/testing_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ccab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from PIL import Image\n",
    "\n",
    "IMG_DIR = \"/kaggle/working/UFPR-ALPR_dataset/validation\"   # where images live\n",
    "LBL_DIR = \"/kaggle/working/UFPR-ALPR_dataset/validation\"   # where labels live\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "# If you ALSO want to convert detect-format YOLO (class cx cy w h) into axis-aligned OBB,\n",
    "# set this True. Otherwise we leave detect labels unchanged.\n",
    "MAKE_OBB_FROM_DETECT = False\n",
    "\n",
    "def find_image(lbl_path):\n",
    "    stem = os.path.splitext(os.path.basename(lbl_path))[0]\n",
    "    # labels may be in a separate folder; we scan IMG_DIR for a matching basename\n",
    "    for root, _, files in os.walk(IMG_DIR):\n",
    "        for f in files:\n",
    "            n, e = os.path.splitext(f)\n",
    "            if n == stem and e.lower() in IMG_EXTS:\n",
    "                return os.path.join(root, f)\n",
    "    return None\n",
    "\n",
    "def clamp01(v): \n",
    "    return 0.0 if v < 0 else 1.0 if v > 1 else v\n",
    "\n",
    "converted = skipped = 0\n",
    "for lbl_path in glob.glob(os.path.join(LBL_DIR, \"**/*.txt\"), recursive=True):\n",
    "    img_path = find_image(lbl_path)\n",
    "    if not img_path:\n",
    "        print(f\"[skip] no image for {lbl_path}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    with Image.open(img_path) as im:\n",
    "        W, H = im.size\n",
    "\n",
    "    out = []\n",
    "    changed = False\n",
    "    with open(lbl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in (ln.strip() for ln in f if ln.strip()):\n",
    "            parts = raw.split()\n",
    "            if len(parts) < 2: \n",
    "                continue\n",
    "            cls = parts[0]\n",
    "            nums = parts[1:]\n",
    "\n",
    "            # ---- Case A: OBB (class + 8 coords)\n",
    "            if len(nums) == 8:\n",
    "                try:\n",
    "                    vals = [float(x) for x in nums]\n",
    "                except:\n",
    "                    print(f\"[warn] non-numeric OBB in {lbl_path}: {raw}\")\n",
    "                    continue\n",
    "\n",
    "                # Decide if pixel or already normalized:\n",
    "                # If any coord > 1.5, we treat as pixel coordinates.\n",
    "                if any(abs(v) > 1.5 for v in vals):\n",
    "                    # normalize x by W and y by H, preserving order x1 y1 x2 y2 ...\n",
    "                    norm = []\n",
    "                    for i, v in enumerate(vals):\n",
    "                        if i % 2 == 0:   # x\n",
    "                            norm.append(clamp01(v / W))\n",
    "                        else:            # y\n",
    "                            norm.append(clamp01(v / H))\n",
    "                    out.append(\" \".join([cls] + [f\"{v:.6f}\" for v in norm]))\n",
    "                    changed = True\n",
    "                else:\n",
    "                    # Already normalized [0,1] ‚Äî keep\n",
    "                    out.append(raw)\n",
    "\n",
    "            # ---- Case B: Detect (class + cx cy w h). By default we leave as-is.\n",
    "            elif len(nums) == 4:\n",
    "                if not MAKE_OBB_FROM_DETECT:\n",
    "                    out.append(raw)  # unchanged\n",
    "                else:\n",
    "                    # Optional: convert detect ‚Üí axis-aligned OBB\n",
    "                    try:\n",
    "                        cx, cy, w, h = map(float, nums)\n",
    "                    except:\n",
    "                        print(f\"[warn] non-numeric detect in {lbl_path}: {raw}\")\n",
    "                        continue\n",
    "                    # If looks like pixels, normalize first\n",
    "                    if max(abs(cx), abs(cy), abs(w), abs(h)) > 1.5:\n",
    "                        cx, cy, w, h = cx / W, cy / H, w / W, h / H\n",
    "                    w = max(1e-6, min(1.0, w)); h = max(1e-6, min(1.0, h))\n",
    "                    cx = clamp01(cx); cy = clamp01(cy)\n",
    "                    x1, y1 = cx - w/2, cy - h/2\n",
    "                    x2, y2 = cx + w/2, cy - h/2\n",
    "                    x3, y3 = cx + w/2, cy + h/2\n",
    "                    x4, y4 = cx - w/2, cy + h/2\n",
    "                    out.append(f\"{cls} {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} {x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}\")\n",
    "                    changed = True\n",
    "\n",
    "            else:\n",
    "                print(f\"[warn] Unexpected field count ({len(nums)}) in {lbl_path}: {raw}\")\n",
    "\n",
    "    if not out:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Backup once\n",
    "    bak = lbl_path + \".bak\"\n",
    "    if not os.path.exists(bak):\n",
    "        with open(bak, \"w\", encoding=\"utf-8\") as b:\n",
    "            with open(lbl_path, \"r\", encoding=\"utf-8\") as src:\n",
    "                b.write(src.read())\n",
    "\n",
    "    with open(lbl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(out) + \"\\n\")\n",
    "\n",
    "    converted += 1 if changed else 0\n",
    "\n",
    "print(f\"Done. Files_changed={converted}, Files_unchanged={len(list(glob.iglob(os.path.join(LBL_DIR, '**/*.txt'), recursive=True))) - converted}, Skipped={skipped}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
